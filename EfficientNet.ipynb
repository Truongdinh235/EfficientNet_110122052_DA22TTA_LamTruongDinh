{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# 1. Cáº¤U HÃŒNH\nDATA_DIR = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\n# 2. Táº O GENERATOR Vá»šI AUGMENTATION (TÄƒng cÆ°á»ng dá»¯ liá»‡u)\n# GiÃºp model khÃ´ng há»c váº¹t vá»‹ trÃ­ xÆ°Æ¡ng sÆ°á»n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,      # Xoay nháº¹\n    width_shift_range=0.1,  # Dá»‹ch ngang\n    height_shift_range=0.1, # Dá»‹ch dá»c\n    shear_range=0.1,\n    zoom_range=0.2,         # PhÃ³ng to Ä‘á»ƒ nhÃ¬n rÃµ phá»•i\n    horizontal_flip=False,  # KHÃ”NG láº­t ngang (tim bÃªn trÃ¡i)\n    fill_mode='nearest',\n    validation_split=0.2    # Láº¥y 20% train lÃ m val\n)\nprint(\" Äang load dá»¯ liá»‡u...\")\ntrain_generator = train_datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\nval_generator = train_datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n# 3. TÃNH TRá»ŒNG Sá» Lá»šP (CLASS WEIGHTS)\n# Äá»ƒ trá»‹ viá»‡c model chá»‰ Ä‘oÃ¡n toÃ n lÃ  \"Pneumonia\" (74%)\n# Normal (0) Ã­t hÆ¡n, nÃªn cáº§n trá»ng sá»‘ cao hÆ¡n.\n# Giáº£ sá»­: Normal ~1300 áº£nh, Pneumonia ~3800 áº£nh -> Tá»‰ lá»‡ ~1:3\nclass_weights = {0: 3.0, 1: 1.0} \nclass_weights = {0: 3.0, 1: 1.0}\nprint(\"âœ… ÄÃ£ sá»­a dá»¯ liá»‡u xong! Sáºµn sÃ ng training.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-10T05:44:39.345864Z","iopub.execute_input":"2026-01-10T05:44:39.346440Z","iopub.status.idle":"2026-01-10T05:44:40.503243Z","shell.execute_reply.started":"2026-01-10T05:44:39.346411Z","shell.execute_reply":"2026-01-10T05:44:40.502636Z"}},"outputs":[{"name":"stdout","text":" Äang load dá»¯ liá»‡u...\nFound 4173 images belonging to 2 classes.\nFound 1043 images belonging to 2 classes.\nâœ… ÄÃ£ sá»­a dá»¯ liá»‡u xong! Sáºµn sÃ ng training.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1. Táº£i EfficientNetB0 \nbase_model = EfficientNetB0(\n    weights='imagenet', \n    include_top=False, \n    input_shape=(224, 224, 3)\n)\n# 2. ÄÃ³ng bÄƒng toÃ n bá»™ base model\nbase_model.trainable = False\n# 3. ThÃªm pháº§n Ä‘áº§u má»›i (Classification Head)\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.BatchNormalization(), # GiÃºp á»•n Ä‘á»‹nh dá»¯ liá»‡u\n    layers.Dropout(0.3),         # Chá»‘ng há»c váº¹t \n    layers.Dense(1, activation='sigmoid') # 1 Ä‘áº§u ra: 0 hoáº·c 1\n])\n# 4. Compile mÃ´ hÃ¬nh\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=1e-3), # Tá»‘c Ä‘á»™ há»c tiÃªu chuáº©n\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T05:44:45.736859Z","iopub.execute_input":"2026-01-10T05:44:45.737522Z","iopub.status.idle":"2026-01-10T05:44:50.893321Z","shell.execute_reply.started":"2026-01-10T05:44:45.737493Z","shell.execute_reply":"2026-01-10T05:44:50.892727Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1768023886.505716      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m4,049,571\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚         \u001b[38;5;34m5,120\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚         \u001b[38;5;34m1,281\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,055,972\u001b[0m (15.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,055,972</span> (15.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,841\u001b[0m (15.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,841</span> (15.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,052,131\u001b[0m (15.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,131</span> (15.46 MB)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\" GIAI ÄOáº N 1: HUáº¤N LUYá»†N KHá»I Äá»˜NG (Warm-up)...\")\nhistory_warmup = model.fit(\n    train_generator,\n    epochs=10,  # Cháº¡y 10 vÃ²ng\n    validation_data=val_generator,\n    class_weight=class_weights \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T06:05:37.386523Z","iopub.execute_input":"2026-01-10T06:05:37.386816Z","iopub.status.idle":"2026-01-10T06:19:56.301592Z","shell.execute_reply.started":"2026-01-10T06:05:37.386790Z","shell.execute_reply":"2026-01-10T06:19:56.300775Z"}},"outputs":[{"name":"stdout","text":" GIAI ÄOáº N 1: HUáº¤N LUYá»†N KHá»I Äá»˜NG (Warm-up)...\nEpoch 1/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 334ms/step - accuracy: 0.9267 - loss: 0.2658 - val_accuracy: 0.9473 - val_loss: 0.1393\nEpoch 2/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 329ms/step - accuracy: 0.9311 - loss: 0.2440 - val_accuracy: 0.9501 - val_loss: 0.1288\nEpoch 3/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 327ms/step - accuracy: 0.9402 - loss: 0.2310 - val_accuracy: 0.9453 - val_loss: 0.1609\nEpoch 4/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 331ms/step - accuracy: 0.9299 - loss: 0.2615 - val_accuracy: 0.9396 - val_loss: 0.1469\nEpoch 5/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 325ms/step - accuracy: 0.9342 - loss: 0.2445 - val_accuracy: 0.9252 - val_loss: 0.1721\nEpoch 6/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 325ms/step - accuracy: 0.9282 - loss: 0.2536 - val_accuracy: 0.9482 - val_loss: 0.1537\nEpoch 7/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 326ms/step - accuracy: 0.9425 - loss: 0.2399 - val_accuracy: 0.9444 - val_loss: 0.1214\nEpoch 8/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 331ms/step - accuracy: 0.9302 - loss: 0.2621 - val_accuracy: 0.9291 - val_loss: 0.1906\nEpoch 9/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 331ms/step - accuracy: 0.9296 - loss: 0.2672 - val_accuracy: 0.9425 - val_loss: 0.1600\nEpoch 10/10\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 330ms/step - accuracy: 0.9250 - loss: 0.2680 - val_accuracy: 0.9540 - val_loss: 0.1373\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras import layers, optimizers, callbacks\nprint(\" ÄANG CHUáº¨N Bá»Š GIAI ÄOáº N 2: FINE-TUNING...\")\n# 1. UNFREEZE (Má»Ÿ khÃ³a thÃ´ng minh)\nbase_model.trainable = True # Cho phÃ©p base model há»c\n# Duyá»‡t qua tá»«ng lá»›p Ä‘á»ƒ cáº¥u hÃ¬nh láº¡i\nfor layer in base_model.layers:\n    # A. Báº®T BUá»˜C KHÃ“A BatchNormalization (Náº¿u khÃ´ng accuracy sáº½ tá»¥t tháº£m háº¡i)\n    if isinstance(layer, layers.BatchNormalization):\n        layer.trainable = False  \n    else:\n        layer.trainable = False \n# Má»Ÿ khÃ³a 30 lá»›p cuá»‘i \nfor layer in base_model.layers[-30:]:\n    if not isinstance(layer, layers.BatchNormalization):\n        layer.trainable = True\n# Kiá»ƒm tra nhanh xem cÃ³ bao nhiÃªu lá»›p Ä‘Æ°á»£c má»Ÿ\ntrainable_count = sum([1 for layer in base_model.layers if layer.trainable])\nprint(f\" ÄÃ£ má»Ÿ khÃ³a {trainable_count} lá»›p cuá»‘i cÃ¹ng Ä‘á»ƒ tinh chá»‰nh.\")\n# 2. COMPILE Láº I (Vá»›i Learning Rate nhá» hÆ¡n 10 láº§n)\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=1e-5), \n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n# 3. Cáº¤U HÃŒNH CALLBACKS (KiÃªn nháº«n hÆ¡n)\ncallbacks_finetune = [\n    callbacks.ModelCheckpoint('best_model_stage2.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n    # Giáº£m tá»‘c Ä‘á»™ há»c náº¿u bá»‹ káº¹t\n    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1),\n    # Cho phÃ©p cháº¡y tá»‘i Ä‘a, dá»«ng náº¿u khÃ´ng khÃ¡ hÆ¡n sau 8 vÃ²ng\n    callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n]\nprint(\" Báº®T Äáº¦U CHáº Y GIAI ÄOáº N 2 (Má»¥c tiÃªu > 95%)...\")\nhistory_finetune = model.fit(\n    train_generator,\n    epochs=50, # Cháº¡y thÃªm 50 vÃ²ng ná»¯a\n    validation_data=val_generator,\n    class_weight=class_weights, # Váº«n giá»¯ trá»ng sá»‘ lá»›p\n    callbacks=callbacks_finetune\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T06:20:03.603920Z","iopub.execute_input":"2026-01-10T06:20:03.604249Z"}},"outputs":[{"name":"stdout","text":" ÄANG CHUáº¨N Bá»Š GIAI ÄOáº N 2: FINE-TUNING...\n ÄÃ£ má»Ÿ khÃ³a 23 lá»›p cuá»‘i cÃ¹ng Ä‘á»ƒ tinh chá»‰nh.\n Báº®T Äáº¦U CHáº Y GIAI ÄOáº N 2 (Má»¥c tiÃªu > 95%)...\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2026-01-10 06:20:18.767513: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:20:18.973585: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:20:19.405697: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:20:19.611573: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m213/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 265ms/step - accuracy: 0.9372 - loss: 0.2535","output_type":"stream"},{"name":"stderr","text":"2026-01-10 06:21:27.062844: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:27.269661: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:27.686252: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:27.890976: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:28.099807: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:28.307817: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:28.469493: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.9 = (f32[1152,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,1152,7,7]{3,2,1,0} %bitcast.38952, f32[13,1152,7,7]{3,2,1,0} %bitcast.38954), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=1152, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"DepthwiseConv2dNativeBackpropFilter\" op_name=\"gradient_tape/sequential_1/efficientnetb0_1/block7a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n2026-01-10 06:21:28.517772: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:28.722961: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n2026-01-10 06:21:28.751239: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.28189887s\nTrying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.9 = (f32[1152,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[13,1152,7,7]{3,2,1,0} %bitcast.38952, f32[13,1152,7,7]{3,2,1,0} %bitcast.38954), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, feature_group_count=1152, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"DepthwiseConv2dNativeBackpropFilter\" op_name=\"gradient_tape/sequential_1/efficientnetb0_1/block7a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9372 - loss: 0.2505\nEpoch 1: val_accuracy improved from -inf to 0.94343, saving model to best_model_stage2.keras\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 421ms/step - accuracy: 0.9372 - loss: 0.2505 - val_accuracy: 0.9434 - val_loss: 0.1477 - learning_rate: 1.0000e-05\nEpoch 2/50\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9350 - loss: 0.2516\nEpoch 2: val_accuracy improved from 0.94343 to 0.94727, saving model to best_model_stage2.keras\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 331ms/step - accuracy: 0.9350 - loss: 0.2515 - val_accuracy: 0.9473 - val_loss: 0.1272 - learning_rate: 1.0000e-05\nEpoch 3/50\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9485 - loss: 0.1956\nEpoch 3: val_accuracy improved from 0.94727 to 0.95590, saving model to best_model_stage2.keras\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 337ms/step - accuracy: 0.9485 - loss: 0.1956 - val_accuracy: 0.9559 - val_loss: 0.1264 - learning_rate: 1.0000e-05\nEpoch 4/50\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9426 - loss: 0.2255\nEpoch 4: val_accuracy did not improve from 0.95590\n\u001b[1m261/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 327ms/step - accuracy: 0.9426 - loss: 0.2255 - val_accuracy: 0.9482 - val_loss: 0.1379 - learning_rate: 1.0000e-05\nEpoch 5/50\n\u001b[1m189/261\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m18s\u001b[0m 261ms/step - accuracy: 0.9405 - loss: 0.2212","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_stage1_history(history):\n    # Láº¥y dá»¯ liá»‡u tá»« lá»‹ch sá»­ huáº¥n luyá»‡n\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(1, len(acc) + 1)\n    plt.figure(figsize=(15, 6))\n    # 1. Biá»ƒu Ä‘á»“ Äá»™ chÃ­nh xÃ¡c (CÃ ng cao cÃ ng tá»‘t)\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Train Accuracy (Há»c)', marker='o')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy (Thi thá»­)', marker='o', linestyle='--')\n    plt.title('Äá»˜ CHÃNH XÃC (Giai Ä‘oáº¡n 1)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    # 2. Biá»ƒu Ä‘á»“ Sai sá»‘ (CÃ ng tháº¥p cÃ ng tá»‘t)\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Train Loss (Há»c)', marker='o')\n    plt.plot(epochs_range, val_loss, label='Validation Loss (Thi thá»­)', marker='o', linestyle='--')\n    plt.title('SAI Sá» LOSS (Giai Ä‘oáº¡n 1)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n# Gá»i hÃ m Ä‘á»ƒ váº½\nplot_stage1_history(history_warmup)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:29:10.904248Z","iopub.execute_input":"2026-01-10T04:29:10.904752Z","iopub.status.idle":"2026-01-10T04:29:11.221999Z","shell.execute_reply.started":"2026-01-10T04:29:10.904723Z","shell.execute_reply":"2026-01-10T04:29:11.221285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1.Äá»™ chÃ­nh xÃ¡c (Accuracy): Báº¡n sáº½ tháº¥y nÃ³ khÃ´ng tÄƒng vá»t nhÆ° Giai Ä‘oáº¡n 1 mÃ  sáº½ nhÃ­ch ráº¥t cháº­m (vÃ­ dá»¥ tá»« 93% -> 94% -> 95%). ÄÆ°á»ng mÃ u cam (Validation) cÃ ng cao vÃ  á»•n Ä‘á»‹nh cÃ ng tá»‘t.\n\n2.Sai sá»‘ (Loss): Quan trá»ng nháº¥t lÃ  Ä‘Æ°á»ng mÃ u cam khÃ´ng Ä‘Æ°á»£c tÄƒng vá»t lÃªn. Náº¿u nÃ³ Ä‘i ngang hoáº·c giáº£m nháº¹ lÃ  ráº¥t tá»‘t. Náº¿u nÃ³ báº¯t Ä‘áº§u Ä‘i lÃªn trong khi Ä‘Æ°á»ng mÃ u xanh Ä‘i xuá»‘ng, Ä‘Ã³ lÃ  dáº¥u hiá»‡u Overfitting","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_stage2_history(history):\n    # Láº¥y dá»¯ liá»‡u\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(1, len(acc) + 1)\n    plt.figure(figsize=(15, 6))\n    # 1. Biá»ƒu Ä‘á»“ Äá»™ chÃ­nh xÃ¡c\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Train Accuracy (Fine-tune)', marker='o', color='blue')\n    plt.plot(epochs_range, val_acc, label='Validation Accuracy (Fine-tune)', marker='o', linestyle='--', color='orange')\n    plt.title('Äá»˜ CHÃNH XÃC (Giai Ä‘oáº¡n 2 - Tinh chá»‰nh)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    # 2. Biá»ƒu Ä‘á»“ Sai sá»‘ (Loss)\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Train Loss (Fine-tune)', marker='o', color='blue')\n    plt.plot(epochs_range, val_loss, label='Validation Loss (Fine-tune)', marker='o', linestyle='--', color='orange')\n    plt.title('SAI Sá» LOSS (Giai Ä‘oáº¡n 2 - Tinh chá»‰nh)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n# Gá»i hÃ m Ä‘á»ƒ váº½\nif 'history_finetune' in locals():\n    plot_stage2_history(history_finetune)\nelse:\n    print(\" Báº¡n chÆ°a cháº¡y xong Giai Ä‘oáº¡n 2 hoáº·c biáº¿n 'history_finetune' chÆ°a tá»“n táº¡i.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:29:16.892660Z","iopub.execute_input":"2026-01-10T04:29:16.892992Z","iopub.status.idle":"2026-01-10T04:29:17.197637Z","shell.execute_reply.started":"2026-01-10T04:29:16.892963Z","shell.execute_reply":"2026-01-10T04:29:17.197020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n# Load mÃ´ hÃ¬nh\nMODEL_PATH = 'best_model_stage2.keras'\nclass_names = {0: 'BÃ¬nh thÆ°á»ng (Normal)', 1: 'ViÃªm phá»•i (Pneumonia)'}\ntry:\n    print(f\"â³ Äang táº£i mÃ´ hÃ¬nh tá»«: {MODEL_PATH}...\")\n    best_model = tf.keras.models.load_model(MODEL_PATH)\n    # Láº¥y batch áº£nh má»›i\n    images, labels = next(val_generator)\n    predictions = best_model.predict(images, verbose=0)\n    plt.figure(figsize=(15, 15))\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)  \n        # 1. Sá»­a lá»—i hiá»ƒn thá»‹ áº£nh tráº¯ng (Ã©p vá» int)\n        img_to_show = images[i]\n        # Xá»­ lÃ½ Ä‘á»ƒ áº£nh hiá»‡n Ä‘áº¹p hÆ¡n dÃ¹ Ä‘Ã£ qua preprocess\n        if np.max(img_to_show) <= 1:\n            img_to_show = (img_to_show * 255).astype('uint8')\n        else:\n            img_to_show = img_to_show.astype('uint8')     \n        plt.imshow(img_to_show)\n        plt.axis('off')\n        # 2. Xá»­ lÃ½ Logic dá»± Ä‘oÃ¡n\n        true_label_idx = int(labels[i])\n        pred_prob = predictions[i][0] # VÃ­ dá»¥: 0.02 hoáº·c 0.98 \n        if pred_prob > 0.5:\n            pred_label_idx = 1 # Pneumonia\n            confidence = pred_prob # Giá»¯ nguyÃªn (0.98 -> 98%)\n        else:\n            pred_label_idx = 0 # Normal\n            confidence = 1 - pred_prob # Äáº£o ngÆ°á»£c (0.02 -> 1-0.02 = 0.98 -> 98%)\n        true_text = class_names[true_label_idx]\n        pred_text = class_names[pred_label_idx]\n        \n        # MÃ u sáº¯c: Xanh = ÄÃºng, Äá» = Sai\n        color = 'green' if true_label_idx == pred_label_idx else 'red'\n        # Hiá»ƒn thá»‹ tiÃªu Ä‘á» Ä‘Ã£ sá»­a logic\n        plt.title(f\"Thá»±c táº¿: {true_text}\\nDá»± Ä‘oÃ¡n: {pred_text}\\n(Äá»™ tin cáº­y: {confidence*100:.2f}%)\", \n                  color=color, fontsize=12, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\nexcept Exception as e:\n    print(f\"Lá»—i: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:29:25.927784Z","iopub.execute_input":"2026-01-10T04:29:25.928132Z","iopub.status.idle":"2026-01-10T04:29:34.686743Z","shell.execute_reply.started":"2026-01-10T04:29:25.928106Z","shell.execute_reply":"2026-01-10T04:29:34.686014Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ÄÆ°á»ng káº» dá»c mÃ u xanh lÃ¡: LÃ  ranh giá»›i.\nBÃªn trÃ¡i lÃ  Giai Ä‘oáº¡n 1.\nBÃªn pháº£i lÃ  Giai Ä‘oáº¡n 2.\nNáº¿u Ä‘Æ°á»ng mÃ u cam (Validation) Ä‘i lÃªn sau váº¡ch xanh: NghÄ©a lÃ  chiáº¿n thuáº­t Fine-tuning cá»§a báº¡n thÃ nh cÃ´ng rá»±c rá»¡.\nPháº§n BÃ¡o cÃ¡o bÃªn dÆ°á»›i: Sáº½ cho báº¡n con sá»‘ chÃ­nh xÃ¡c Ä‘á»ƒ viáº¿t vÃ o bÃ i bÃ¡o cÃ¡o (VÃ­ dá»¥: \"Sau khi tinh chá»‰nh, mÃ´ hÃ¬nh tÄƒng tá»« 93.1% lÃªn 96.5%\").","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Kiá»ƒm tra xem báº¡n Ä‘Ã£ cháº¡y Ä‘á»§ 2 giai Ä‘oáº¡n chÆ°a\nif 'history_warmup' in locals() and 'history_finetune' in locals():\n    \n    # --- 1. Gá»˜P Dá»® LIá»†U ---\n    # Ná»‘i Ä‘uÃ´i dá»¯ liá»‡u giai Ä‘oáº¡n 2 vÃ o sau giai Ä‘oáº¡n 1\n    acc = history_warmup.history['accuracy'] + history_finetune.history['accuracy']\n    val_acc = history_warmup.history['val_accuracy'] + history_finetune.history['val_accuracy']\n    loss = history_warmup.history['loss'] + history_finetune.history['loss']\n    val_loss = history_warmup.history['val_loss'] + history_finetune.history['val_loss']\n\n    # Äiá»ƒm cáº¯t (nÆ¡i báº¯t Ä‘áº§u giai Ä‘oáº¡n 2)\n    start_finetune = len(history_warmup.history['accuracy'])\n\n    # --- 2. Váº¼ BIá»‚U Äá»’ SO SÃNH ---\n    plt.figure(figsize=(15, 6))\n\n    # Biá»ƒu Ä‘á»“ Äá»™ chÃ­nh xÃ¡c\n    plt.subplot(1, 2, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    # Váº½ Ä‘Æ°á»ng káº» dá»c mÃ u xanh lÃ¡ Ä‘á»ƒ Ä‘Ã¡nh dáº¥u má»‘c Giai Ä‘oáº¡n 2\n    plt.axvline(x=start_finetune, color='green', linestyle='--', label='Báº¯t Ä‘áº§u Fine-tuning')\n    plt.title('So sÃ¡nh Äá»™ chÃ­nh xÃ¡c (Accuracy)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n\n    # Biá»ƒu Ä‘á»“ Sai sá»‘ (Loss)\n    plt.subplot(1, 2, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.axvline(x=start_finetune, color='green', linestyle='--', label='Báº¯t Ä‘áº§u Fine-tuning')\n    plt.title('So sÃ¡nh Sai sá»‘ (Loss)')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\n    # --- 3. BÃO CÃO Káº¾T QUáº¢ Cá»¤ THá»‚ ---\n    best_acc_1 = max(history_warmup.history['val_accuracy'])\n    best_acc_2 = max(history_finetune.history['val_accuracy'])\n    improvement = best_acc_2 - best_acc_1\n\n    print(\"-\" * 50)\n    print(\" BÃO CÃO HIá»†U QUáº¢ NÃ‚NG Cáº¤P:\")\n    print(f\"1. Äá»‰nh cao Giai Ä‘oáº¡n 1 (Warm-up):  {best_acc_1*100:.2f}%\")\n    print(f\"2. Äá»‰nh cao Giai Ä‘oáº¡n 2 (Fine-tune): {best_acc_2*100:.2f}%\")\n    print(\"-\" * 50)\n    if improvement > 0:\n        print(f\" Káº¾T LUáº¬N: Viá»‡c Fine-tuning Ä‘Ã£ giÃºp mÃ´ hÃ¬nh tÄƒng thÃªm {improvement*100:.2f}% Ä‘á»™ chÃ­nh xÃ¡c!\")\n    else:\n        print(f\" Káº¾T LUáº¬N: Giai Ä‘oáº¡n 2 khÃ´ng tÄƒng thÃªm Ä‘á»™ chÃ­nh xÃ¡c (CÃ³ thá»ƒ GÄ1 Ä‘Ã£ quÃ¡ tá»‘t rá»“i).\")\n    print(\"-\" * 50)\n\nelse:\n    print(\" Lá»–I: Báº¡n chÆ°a cháº¡y xong Giai Ä‘oáº¡n 2 hoáº·c biáº¿n 'history_finetune' khÃ´ng tá»“n táº¡i.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:29:40.621250Z","iopub.execute_input":"2026-01-10T04:29:40.621873Z","iopub.status.idle":"2026-01-10T04:29:40.964501Z","shell.execute_reply.started":"2026-01-10T04:29:40.621822Z","shell.execute_reply":"2026-01-10T04:29:40.963803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- BÆ¯á»šC 1: CHUáº¨N Bá»Š Dá»® LIá»†U KIá»‚M TRA (QUAN TRá»ŒNG) ---\n# Táº¡o láº¡i generator cho táº­p Validation nhÆ°ng táº¯t cháº¿ Ä‘á»™ trÃ¡o bÃ i (shuffle=False)\n# Äá»ƒ Ä‘áº£m báº£o thá»© tá»± áº£nh vÃ  nhÃ£n khá»›p nhau 1-1\nprint(\"ğŸ”„ Äang chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ cháº¥m Ä‘iá»ƒm...\")\n\nval_generator_final = train_datagen.flow_from_directory(\n    DATA_DIR, # DÃ¹ng láº¡i Ä‘Æ°á»ng dáº«n thÆ° má»¥c train\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False # <--- Báº®T BUá»˜C PHáº¢I LÃ€ FALSE\n)\n\n# --- BÆ¯á»šC 2: Dá»° ÄOÃN ---\nprint(\"ğŸ§ Äang 'khÃ¡m' láº¡i toÃ n bá»™ táº­p Validation...\")\n# Load mÃ´ hÃ¬nh tá»‘t nháº¥t báº¡n Ä‘Ã£ lÆ°u\nbest_model = tf.keras.models.load_model('best_model_stage2.keras')\n\n# Thá»±c hiá»‡n dá»± Ä‘oÃ¡n (káº¿t quáº£ lÃ  xÃ¡c suáº¥t tá»« 0 Ä‘áº¿n 1)\npredictions = best_model.predict(val_generator_final, verbose=1)\n\n# Chuyá»ƒn xÃ¡c suáº¥t thÃ nh nhÃ£n: > 0.5 lÃ  ViÃªm phá»•i (1), ngÆ°á»£c láº¡i lÃ  BÃ¬nh thÆ°á»ng (0)\ny_pred = (predictions > 0.5).astype(int)\n\n# Láº¥y nhÃ£n thá»±c táº¿ tá»« dá»¯ liá»‡u\ny_true = val_generator_final.classes\n\n# --- BÆ¯á»šC 3: Váº¼ MA TRáº¬N NHáº¦M LáºªN ---\n# TÃ­nh toÃ¡n ma tráº­n\ncm = confusion_matrix(y_true, y_pred)\n\n# Váº½ Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['BÃ¬nh thÆ°á»ng (Normal)', 'ViÃªm phá»•i (Pneumonia)'], \n            yticklabels=['BÃ¬nh thÆ°á»ng (Normal)', 'ViÃªm phá»•i (Pneumonia)'])\nplt.xlabel('Dá»± Ä‘oÃ¡n cá»§a AI', fontsize=12)\nplt.ylabel('Thá»±c táº¿ (BÃ¡c sÄ©)', fontsize=12)\nplt.title('MA TRáº¬N NHáº¦M LáºªN (CONFUSION MATRIX)', fontsize=14, fontweight='bold')\nplt.show()\n\n# --- BÆ¯á»šC 4: BÃO CÃO CHI TIáº¾T ---\n# In ra báº£ng Precision, Recall, F1-Score nhÆ° trong hÃ¬nh báº¡n gá»­i\nprint(\"\\nğŸ“Š BÃO CÃO CHI TIáº¾T:\")\ntarget_names = ['Normal (BÃ¬nh thÆ°á»ng)', 'Pneumonia (ViÃªm phá»•i)']\nprint(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:29:45.607710Z","iopub.execute_input":"2026-01-10T04:29:45.608032Z","iopub.status.idle":"2026-01-10T04:30:24.242089Z","shell.execute_reply.started":"2026-01-10T04:29:45.608005Z","shell.execute_reply":"2026-01-10T04:30:24.241401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- Dá»® LIá»†U Tá»ª BÃO CÃO (File HÃ£n.pptx) ---\n# Giai Ä‘oáº¡n 1: Feature Extraction (ÄÃ³ng bÄƒng backbone)\n# Giai Ä‘oáº¡n 2: Fine-Tuning (Má»Ÿ khÃ³a Layer 300+, LR tháº¥p)\n\ndata = {\n    'Chá»‰ sá»‘ (Metrics)': ['Äá»™ chÃ­nh xÃ¡c (Accuracy)', 'Äá»™ nháº¡y (Recall - Pneumonia)', 'Tá»· lá»‡ bá» sÃ³t (False Negative)'],\n    'Giai Ä‘oáº¡n 1 (CÆ¡ báº£n)': [94.8, 97.2, 2.8],\n    'Giai Ä‘oáº¡n 2 (Cáº£i tiáº¿n)': [96.31, 98.7, 1.3]\n}\n\n# ==============================================================================\n# Báº¢N 1: IN Báº¢NG SO SÃNH Sá» LIá»†U (Dáº¡ng Text/DataFrame)\n# ==============================================================================\ndef print_comparison_table():\n    df = pd.DataFrame(data)\n    \n    # TÃ­nh cá»™t \"Má»©c cáº£i thiá»‡n\"\n    df['Cáº£i thiá»‡n (+/-)'] = df['Giai Ä‘oáº¡n 2 (Cáº£i tiáº¿n)'] - df['Giai Ä‘oáº¡n 1 (CÆ¡ báº£n)']\n    df['Cáº£i thiá»‡n (+/-)'] = df['Cáº£i thiá»‡n (+/-)'].apply(lambda x: f\"+{x:.2f}%\" if x > 0 else f\"{x:.2f}%\")\n    \n    # ThÃªm Ä‘Æ¡n vá»‹ % vÃ o hiá»ƒn thá»‹\n    df_display = df.copy()\n    df_display['Giai Ä‘oáº¡n 1 (CÆ¡ báº£n)'] = df_display['Giai Ä‘oáº¡n 1 (CÆ¡ báº£n)'].astype(str) + '%'\n    df_display['Giai Ä‘oáº¡n 2 (Cáº£i tiáº¿n)'] = df_display['Giai Ä‘oáº¡n 2 (Cáº£i tiáº¿n)'].astype(str) + '%'\n\n    print(\"=\"*60)\n    print(\" Báº¢NG 1: SO SÃNH HIá»†U QUáº¢ GIá»®A 2 GIAI ÄOáº N HUáº¤N LUYá»†N\")\n    print(\"=\"*60)\n    print(df_display.to_string(index=False))\n    print(\"-\" * 60)\n    print(\"NHáº¬N XÃ‰T: Sau khi Fine-tuning, tá»· lá»‡ bá» sÃ³t bá»‡nh giáº£m hÆ¡n 50% (tá»« 2.8% xuá»‘ng 1.3%).\")\n    print(\"=\"*60 + \"\\n\")\n\n# ==============================================================================\n# Báº¢N 2: Váº¼ BIá»‚U Äá»’ SO SÃNH TRá»°C QUAN (Bar Chart)\n# ==============================================================================\ndef plot_comparison_chart():\n    # Chá»‰ láº¥y 2 chá»‰ sá»‘ quan trá»ng Ä‘á»ƒ váº½: Accuracy vÃ  Recall\n    metrics = ['Accuracy (Äá»™ chÃ­nh xÃ¡c)', 'Recall (Äá»™ nháº¡y)']\n    stage1_vals = [94.8, 97.2]\n    stage2_vals = [96.31, 98.7]\n\n    x = np.arange(len(metrics))  # Vá»‹ trÃ­ cÃ¡c nhÃ£n\n    width = 0.35  # Äá»™ rá»™ng cá»™t\n\n    fig, ax = plt.subplots(figsize=(8, 6))\n    \n    # Váº½ 2 cá»™t\n    rects1 = ax.bar(x - width/2, stage1_vals, width, label='GÄ1: Feature Extraction', color='#B0BEC5') # MÃ u xÃ¡m\n    rects2 = ax.bar(x + width/2, stage2_vals, width, label='GÄ2: Fine-Tuning (Cáº£i tiáº¿n)', color='#00897B') # MÃ u xanh Teal\n\n    # Trang trÃ­ biá»ƒu Ä‘á»“\n    ax.set_ylabel('Pháº§n trÄƒm (%)', fontsize=12)\n    ax.set_title('So SÃ¡nh Hiá»‡u Quáº£ MÃ´ HÃ¬nh TrÆ°á»›c & Sau Cáº£i Tiáº¿n', fontsize=14, fontweight='bold', color='#004D40')\n    ax.set_xticks(x)\n    ax.set_xticklabels(metrics, fontsize=12)\n    ax.set_ylim(90, 100) # Zoom vÃ o khoáº£ng 90-100% Ä‘á»ƒ tháº¥y rÃµ chÃªnh lá»‡ch\n    ax.legend()\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n\n    # HÃ m hiá»ƒn thá»‹ sá»‘ trÃªn Ä‘áº§u cá»™t\n    def autolabel(rects):\n        for rect in rects:\n            height = rect.get_height()\n            ax.annotate(f'{height}%',\n                        xy=(rect.get_x() + rect.get_width() / 2, height),\n                        xytext=(0, 3),  # 3 points vertical offset\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom', fontweight='bold')\n\n    autolabel(rects1)\n    autolabel(rects2)\n\n    fig.tight_layout()\n    plt.show()\n\n# --- CHáº Y CHÆ¯Æ NG TRÃŒNH ---\nif __name__ == \"__main__\":\n    print_comparison_table() # In báº£ng\n    plot_comparison_chart()  # Váº½ biá»ƒu Ä‘á»“","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T04:30:30.756766Z","iopub.execute_input":"2026-01-10T04:30:30.757495Z","iopub.status.idle":"2026-01-10T04:30:30.932262Z","shell.execute_reply.started":"2026-01-10T04:30:30.757451Z","shell.execute_reply":"2026-01-10T04:30:30.931630Z"}},"outputs":[],"execution_count":null}]}